{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T13:54:37.092903Z",
     "start_time": "2024-10-23T13:54:34.424660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pipeline.DBHandler import DBHandler\n",
    "import cohere\n",
    "import google.generativeai as genai\n",
    "\n",
    "# semantic chunking imports\n",
    "from semantic_router.splitters import RollingWindowSplitter\n",
    "from semantic_router.encoders import CohereEncoder, OpenAIEncoder\n",
    "from semantic_router.utils.logger import logger\n",
    "\n",
    "logger.setLevel(\"WARNING\")  # reduce logs from splitter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from typing import Union\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ],
   "id": "36b6dd3e56ccff54",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T13:54:39.651468Z",
     "start_time": "2024-10-23T13:54:39.607216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))\n",
    "handler = DBHandler('maccabi_cohere', user_id='evaluator')"
   ],
   "id": "7eae7ce83cdb8ff2",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-20T10:12:45.647702Z",
     "start_time": "2024-10-20T10:12:45.572411Z"
    }
   },
   "source": [
    "def semantic_chunking(encoder: Union[type(CohereEncoder), type(OpenAIEncoder())], directory_path: str, score_threshold: float = 0.4) -> list:\n",
    "\t\"\"\"\n",
    "    Use the semantic chunking to split the documents into semantic chunks\n",
    "    Args:\n",
    "        encoder: an embedding model to use for the semantic chunking\n",
    "        directory_path (str): path to the directory containing the documents\n",
    "        score_threshold (float): the score threshold for the encoder below which the split is made, between 0 and 1\n",
    "    Returns:\n",
    "        splits (list): list of the semantic chunks\n",
    "    \"\"\"\n",
    "\tencoder.score_threshold = score_threshold\n",
    "\tsplitter = RollingWindowSplitter(\n",
    "\t\t# Todo: adjust the parameters according to the dataset\n",
    "\t\tencoder=encoder,\n",
    "\t\tdynamic_threshold=False,\n",
    "\t\tmin_split_tokens=200,\n",
    "\t\tmax_split_tokens=400,\n",
    "\t\twindow_size=5,\n",
    "\t\tplot_splits=True,\n",
    "\t\tenable_statistics=True\n",
    "\t)\n",
    "\n",
    "\tsplits = []\n",
    "\tfor file_name in os.listdir(directory_path):\n",
    "\t\tprint(file_name)\n",
    "\t\tfile = open(f'{directory_path}/{file_name}', \"r\")\n",
    "\t\texample_faq = file.read()\n",
    "\t\tfile.close()\n",
    "\n",
    "\t\tcurrent_splits = splitter([example_faq])\n",
    "\t\tcomplete_current_splits = []\n",
    "\n",
    "\t\tfor i in range(len(current_splits)):\n",
    "\t\t\t# for more context, add 200 chars from the previous and next splits\n",
    "\t\t\tif i == 0:\n",
    "\t\t\t\tcomplete_current_splits.append(' '.join(current_splits[i].docs + current_splits[i + 1].docs[:200]))\n",
    "\t\t\telif i + 1 == len(current_splits):\n",
    "\t\t\t\tcomplete_current_splits.append(' '.join(current_splits[i - 1].docs[-200:] + current_splits[i].docs))\n",
    "\t\t\telse:\n",
    "\t\t\t\tcomplete_current_splits.append(' '.join(\n",
    "\t\t\t\t\tcurrent_splits[i - 1].docs[-200:] + current_splits[i].docs + current_splits[i + 1].docs[:200]))\n",
    "\n",
    "\t\tsplits.extend(complete_current_splits)\n",
    "\treturn splits\n",
    "\n",
    "\n",
    "def google_embedding(text: str, model: str = 'models/text-embedding-004') -> list:\n",
    "\t\"\"\"\n",
    "\tUse the Google Embedding API to embed the text\n",
    "\tArgs:\n",
    "\t\ttext (str): the text to embed\n",
    "\t\tmodel (str): the name of the model to use for the embedding, either 'models/text-embedding-004' or 'models/embedding-001'\n",
    "\tReturns:\n",
    "\t\tembedding (list): the embedding vector of the text\n",
    "\tRaises:\n",
    "\t\tException: if there is an error in embedding the text\n",
    "\t\"\"\"\n",
    "\ttry:\n",
    "\t\tembedding = genai.embed_content(model=model, content=text, task_type='retrieval_document')\n",
    "\texcept Exception as e:\n",
    "\t\traise Exception(f'Error in embedding the text: {e}')\n",
    "\t\t\n",
    "\treturn embedding['embedding']\n",
    "\n",
    "\n",
    "def create_chunks(encoder: Union[type(CohereEncoder), type(OpenAIEncoder())], directory_path: str, score_threshold: float = 0.5, model: str = 'models/text-embedding-004') -> list:\n",
    "\t\"\"\"\n",
    "\tCreate the chunks of the documents and embed them\n",
    "\tArgs:\n",
    "\t\tencoder: an embedding model to use for the semantic chunking\n",
    "\t\tdirectory_path (str): path to the directory containing the documents\n",
    "\t\tscore_threshold (float): the score threshold for the encoder below which the split is made, between 0 and 1\n",
    "\t\tmodel (str): the name of the model to use for the embedding, either 'models/text-embedding-004' or 'models/embedding-001'\n",
    "\tReturns:\n",
    "\t\tchunks (list): list of the chunks with their embeddings\n",
    "\t\"\"\"\n",
    "\tsplits = semantic_chunking(encoder, directory_path, score_threshold)\n",
    "\t\n",
    "\tchunks = []\n",
    "\tfor split in splits:\n",
    "\t\tembedding = google_embedding(split, model)\n",
    "\t\t\n",
    "\t\tchunk = {\n",
    "\t\t\t'text': split,\n",
    "\t\t\t'embedding': embedding\n",
    "\t\t}\n",
    "\t\tchunks.append(chunk)\n",
    "\t\t\n",
    "\treturn chunks\n",
    "\n"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:06:35.610938Z",
     "start_time": "2024-10-20T10:05:09.438237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chunks = create_chunks(CohereEncoder(), 'data/docs', 0.5, 'models/text-embedding-004')\n",
    "handler.update('embeddings', chunks)"
   ],
   "id": "9f858a083ef1f540",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "4ed103988146b759",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
